\section{Radio Access Network}
\label{sec:access}

In this section, we detail the functions executed by the network equipment to enable data transmission. The network equipment needs to acquire \acs{CSI} and manage resources accordingly to cope with the incoming application traffic and fulfil service requirements. Firstly, we go over important considerations and assumptions, namely regarding multi-layer transmissions, concentrating on the \ac{DL}, among other miscellaneous but relevant matters. Then we list the steps required to simulate a \ac{TTI} and all processing associated with making the right choices when transmitting and receiving. We summarise these steps with a flowchart and proceed to detail each one.

Firstly, we opt for a \ac{GoB}-based beamforming approach. With the growing number of antennas at the receivers, full channel knowledge is practically unobtainable, and we need to resort to more overhead-efficient approaches. 

Secondly, we address the considerations regarding multi-layer transmission. To reiterate, the difference between single-layer and multi-layer operation is the number of independent streams transmitted per \ac{UE}. And to transmit independent streams or layers, there must be some orthogonality mechanism that renders such layers independent. The orthogonality domain we are concern with is orthogonality in space. However, by opting \ac{GoB}-based beamforming although we save in overhead, we loose considerably in transmission flexibility. Free-format beamforming would allow us to send independent layers in the same direction, only focusing different antennas at the reception. But using a \ac{GoB} we do not have enough beams to do that, instead we have to resort to completely different propagation paths, with paths beyond the first not being the \ac{LoS}. This would not yield insignificant improvements. 

Another option would be to resort to polarisation orthogonality. Instead of using all antenna elements to perform a transmission, we may use the antennas oriented in a given direction to send one layer and the elements oriented perpendicularly to send another. Note that the same beam in the GoB can be used for the different polarisations when they are to be sent over the same path. However, the moments in time where inter-polarisation interference is small, e.g. less than 20 dB, are rare. In other words, often antennas with a given orientation at the receiver get signal from both polarisations at the transmitter. Thus, it would require considerably more complicated interference estimations algorithms to do multi-layer transmissions polarisation-based. This is why we opt for single-layer transmission using all antennas both in the \ac{TX} and in the \ac{RX}. Nevertheless, the vast majority of modelling in this section is agnostic to the number of layers.

Thirdly, although in Section \ref{sec:sxr_meeting_modelling} we modelled the location of all \acsp{UE} in the system and application traffic for \acs{UL} and \acs{DL}, for conciseness in this section we describe the model for \acs{DL} transmission procedure and thus we do not consider cameras. In the \acs{DL}, he number of UEs $N_{ue}$ equal to the number of physical users $N_{phy}$.

In essence, we need to list all procedures that can happen in a \acs{TTI}. Some may not happen every \acs{TTI} and we need to state in what circumstances they do happen. See in Figure \ref{fig:flowchart_sls} a flowchart of the main steps required to simulate a (\acs{DL}) \acs{TTI}.

\image{Methodology/Radio Access/flowchart.png}{Flowchart for of simulation steps for each TTI.}{fig:flowchart_sls}{.48}

Several verifications are made to decide whether some procedures should take place. The first is to identify the nature of the current \acs{TTI} - UL and DL TTIs have different steps. The second is checking whether CSI should be updated. Thirdly, it is to verify whether the current user scheduling information for that TTI is to be updated. Only after those verifications and respective procedures, the transmissions scheduled for the present TTI are processed. 

The very first step is assessing the nature of the TTI depends on the slot-structure and TDD split.

\subsection*{TDD Split and Slot Format}

We recognise two options. The first is to use self-contained slots, at a cost of about $2/14 \approx 14\%$ lower bitrate since 2 out of 14 symbols are used for guard and control, but having the benefit of feedback about block errors in the same TTI, thus allowing triggering retransmissions of the lost information the next TTI. This way the likelihood of packet dropping due to transgressions of time constrains is reduced since latency is reduced, leading to more opportunities to transmit the data on time. The second is simpler and more throughput-efficient, at the cost of latency performance. It consists on using slots that only have \ac{DL}/\ac{UL} symbols, respectively, and we ignore the guard time in the transition slot.

Therefore our definition of \ac{UL}/\ac{DL} split, or \ac{TDD} split depends on the option. Let us define $s_{TDD}$ as the ratio between UL and DL slots. We represent this ratio as $N^{DL}_{slots} : N^{UL}_{slots}$, e.g. 4:1, meaning that for each UL slot there are 4 DL slots. The slot structure is completely defined by the number of slots in a transmission period $N^{TDD}_{slots}$.

In order to optionally change between both options, we introduce a transport block acknowledgement delay $\tau_{ACK}$ (in TTIs)  and a slot efficiency $\eta_{slot}$. The acknowledgement delay is the number of TTIs before the transmitter receives the acknowledgement, thus $\tau_{ACK} + 1$ is the number of TTIs until the erroneous transport block can be transmitted again. With self-contained slots, $\tau_{ACK} = 0$. Without self-contained slots it depends on the $s_{TDD}$.

The slot efficiency $\eta_{slot} = 0.86$ in the example of self-contained slots where 14\% of symbols are not used for data, and $\eta_{slot} = 0$ in the DL/UL heavy slots. It is applied to the instantaneous throughput $R$ as $R_{modified} = R \eta_{slot}$

\begin{comment}
Equations \eqref{eq:tdd_split} and \eqref{eq:slot_per}.

\begin{align}
    s_\text{TDD} &= N^\text{DL}_\text{slots} \ / \ N^\text{UL}_\text{slots} \label{eq:tdd_split} \\
    P_\text{slot} &= N^\text{DL}_\text{slots} + N^\text{UL}_\text{slots} \label{eq:slot_per}
\end{align}
\end{comment}

As mentioned, we solely present, and posteriorly evaluate, modelling for DL TTIs. Thus after making the distinction between TTIs, the next step is to update the CSI information based on our beamforming strategy. Therefore, let us first state how the \ac{GoB} is created.

\subsection*{Grid of Beams}
\label{sec:GoB}

To create a GoB we need to know which directions to steer the beam. The beam-steering directions are all possible combinations of values in the azimuthal and elevation angular domains, relative to the antenna boresight (direction perpendicular to the plane the antenna array is inserted). And to create a beam grid in one such domain, one simple way is to use the resolution and the values of the extremes. We define in Equation \eqref{eq:inter_func} an interpolation function to perform the operation of creating a set of values from $a$ to $b$, given $b$ strictly greater than $a$, with intervals of resolution $r$.


\begin{equation} \label{eq:inter_func}
    F_I(a, b, r) = \left\{a + i \times r \  \forall \ i \in \mathbb{N}_0: i \times r \leq b-a \right\}
\end{equation}

This way, we define in the azimuthal angular domain as $\mathcal{A}_\phi = F_I(a_\phi, b_\phi, r_\phi)$ and the elevation angular domain as $\mathcal{A}_\theta = F_I(a_\theta, b_\theta, r_\theta)$. For instance, if the antenna is positioned in the centre of the room, on the ceiling, pointing downwards, then the most logical approach is a symmetric approach because in that position the coverage of the room would be uniform since we consider our room with equal length and width(for room and user behaviour modelling, see Section \ref{sec:sxr_meeting_modelling}). More concretely, the GoB should cover all positions the UEs may potentially be. Thus, given the position and movement of the users in relation to the size of the room described in the example of Section \ref{sec:ue_placement}, choosing the lower limits to $a_\phi = a_\theta = -60\text{\textdegree}$ and the upper limits to $b_\phi = b_\theta = 60\text{\textdegree}$ covers all possible UE positions.

The resolutions should depend on the array size. To create a pseudo-non-interfering GoB, where the maximum of the main lobe of one beam points at the a minimum of an adjacent beam, the resolution should be roughly half the \ac{FNBW}. It is `pseudo-non-interfering' because the \ac{FNBW} varies with the direction at which the beam is steered, which causes the maximums to not align perfectly with the nulls. This effect is unnoticeable in adjacent beams, and gets more noticeable the more far apart beams are from each other. So, this method is a simplistic yet effective approach to minimise the interference between beams, but it does not eliminate this interference. 

Thus, the possible directions are defined as a cartesian product between the azimuthal and elevation domains, shown in Equation \eqref{eq:dir}.

\begin{equation} \label{eq:dir}
    \mathcal{D} = \mathcal{A}_\phi \times \mathcal{A}_\theta = \left\{(\phi, \theta) : \ \phi \in \mathcal{A}_\phi , \ \theta \in \mathcal{A}_\theta\right\}
\end{equation}


Having the directions, we need the precoder that will construct a beam pointing in that direction. In Equation \eqref{eq:prec_func} we define the $M$ by $N$ beamforming matrix $\bm{W}_{\phi, \theta}$ that contains the relative amplitudes and phases that are applied to the signal of each antenna element of an $M$ by $N$ planar array, obtaining as a result a beam directed to $\phi$ degrees on the horizontal plane and $\theta$ degrees on the vertical plane. Note that such planes depend on the orientation of the array and the angles $\phi$ and $\theta$ are null in the interception of both planes, corresponding to the direction orthogonal to the array plane (see Appendix \ref{sec:beam_steering} for a complete derivation).


\begin{align} \label{eq:prec_func}
    \bm{W}_{\phi, \theta}= 
    \begin{bmatrix}
        1 & u_2 & \dots & u_2^{(N-1)}\\
        u_1 & u_1 u_1 & \dots & u_1 u_2^{(N-1)}\\
        \vdots & \vdots & \ddots & \vdots\\
        u_1^{(M-1)} & u_1^{(M-1)} u_2 & \dots & u_1^{(M-1)} u_2^{(N-1)}
    \end{bmatrix}, \ \text{with} \
    \begin{cases}
        u_1 = e^{-j \pi \sin(\phi) \sin(\theta)} \\
        u_2 = e^{-j \pi \cos(\phi) \sin(\theta)}
    \end{cases}
\end{align}


Subsequently, to obtain every precoder in the GoB we need to build a precoding matrix for each direction in $\mathcal{D}$. Let us define in Equation \eqref{eq:W} the set $\mathcal{W}$ containing all precoders $\bm{W}_{\phi, \theta}$ in the GoB, formed for an $M$ by $N$ \ac{URA}.

\begin{equation} \label{eq:W}
    \mathcal{W}^\text{GoB} = \left\{ \bm{W}_{\phi, \theta} : (\phi, \theta) \in \mathcal{D}\right\}
\end{equation}

Figure \ref{fig:GoB} illustrates the result of a cut at zero degrees elevation on beams of two grids. The two grids are built for square antenna arrays, with 16 and 1024 elements, respectively, left and right sides of the figure, hence the noticeably different directivity. Using the 3GPP-defined elements in \cite{3gpp_antennas}, the maximum directivities are 20 dBi and 38 dBi, respectively, for the 16-element array and for the 1024-element array. Furthermore, since the resolutions were purposely set to match half of the \ac{FNBW}, the grid on the left spans 120\textdegree \ of angular domain, from -60\textdegree \ to 60\textdegree, with steps of 30\textdegree, while the grid on the right does so with a resolution of 4\textdegree. In total, this equates to 25 distinct beams of the small array and 961 beams in the larger array.

\image{GoB/gob_paper_final_cut.png}{GoB azimuth cuts for 4 by 4 (left) and a 32 by 32 (right) antenna element array.}{fig:GoB}{.55}


\subsection{Channel State Information}

CSI updates happen every $N^{CSI}_{slots}$ slots or \acsp{TTI}. Not all TTIs have CSI updates because the channel does not change enough to be worth updating that frequently, and due to prohibitive overheads since reference signals are sent in place of data. 

The overheads associated with different \ac{CSI} feedback schemes is not modelled. The overhead would depend on the type and quality of said measurements, thus we simply define a CSI-slot efficiency $\eta_{CSI}$ meant to reduce the bit rate of CSI slots.

CSI is required for operation of two important mechanisms. First, to direct and receive signals optimally, in accordance with the paths where attenuation is lower. As such, it is used to update matching beamformers at the transmitter and receiver, or beam pairs. Second, to assess received power and interference, which are crucial to estimate channel quality, which is then used to, e.g. determine which MCS to use.


\subsubsection*{Beam pairs Update}

To update the best beam pairs between UEs and BS panels, the BS should transmits $N_{CSI}$ beamformed CSI-RSs and the UE reports how well it received each RS. However, this would require a mechanism for the BS to identify, based on previous channel measurements, which beams are more likely to best serve the UE. As such, instead we check all beams in the \ac{GoB} to assess which best suit the channel. Then we keep received power information about $N_{CSI}$ of them.

The best beam pairs are chosen to maximise the channel gain achieved from performing a transmission with a given GoB beam, with a best effort reception using \acs{MRC}. Therefore, for a link between UE $u$ and BS panel $b$, the beamformer on the BS side $\bm{w}^{BS}_{bu}$ is always a beam-steering vector from the GoB, i.e. $\bm{w}^{BS}_{bu} \in \mathcal{W}^{GoB}_b$. And the UE-side beamformer $\bm{w}^{UE}_{bu}$ is always the \ac{MR} beamformer that fits perfectly the use of the BS beamformer and the channel $\bm{h}_{bu}$, given in Equation \ref{eq:GoB_choice_ue}. Thus, $\bm{w}^{BS}_{bu}$ is $N_{ant}^{BS} \times 1$, $\bm{w}^{UE}_{bu}$ is $1 \times N_{ant}^{UE}$, and $\bm{H}_{bu}$ is $N_{ant}^{UE} \times N_{ant}^{BS}$ where $N_{ant}^{UE}$ and $N_{ant}^{BS}$ are the number of single-polarised antenna elements at the UE and BS panel antenna arrays, respectively.


\begin{equation} \label{eq:GoB_choice_ue}
    \bm{w}^{UE}_{bu} = \frac{\left(\bm{H}_{bu} \cdot \bm{w}^{BS}_{bu}\right)^H}{\left|\bm{H}_{bu} \cdot \bm{w}^{BS}_{bu}\right|}
\end{equation}


When $\bm{w}^{UE}$ is a MR beamformer, the channel gain under transmit and receive beamforming is a real number. Therefore, to choose the $\bm{w}$ that achieves the highest gain, we simply have to choose $\bm{w}$ that results in highest norm of its internal product with the channel. This shortcut is represented in \eqref{eq:GoB_choice}. In essence, this means that because we are computing the UE-side beamformer already taking into account the transmit-side beamformer, to maximise the norm of the received signal it is sufficient to choose the appropriately the transmit-side beamformer. 

\begin{equation} \label{eq:GoB_choice}
    \bm{w}^{BS}_{bu} = \argmax_{\bm{w} \ \in \ \mathcal{W}^{GoB}_b} \left| \bm{w}^{UE}_{bu} \cdot \bm{H}_{bu} \cdot \bm{w} \right| = \argmax_{\bm{w} \ \in \ \mathcal{W}^{GoB}_b} \left| \bm{H}_{bu} \cdot \bm{w}\right|
\end{equation}

When $N_{CSI} > 1$, instead of the best beamformer, we save the $N_{CSI}$ best GoB beamformers. For sake of practicality, let us assume $N_{CSI} = 1$ for now on. Furthermore, beam pairs computed in this way profit from beam-reciprocity, i.e. the beams used for receiving can be used for transmitting as well. And doing this way, the received power is already present (see Equation \eqref{eq:rx_pow_ue}), thus we only need to update the interference now.

\begin{equation} \label{eq:rx_pow_ue}
    P_{r, bu}^{UE} = P_{t, bu}^{BS} \left| \bm{w}^{UE}_{bu} \cdot \bm{H}_{bu} \cdot \bm{w}^{BS}_{bu} \right|^2 
\end{equation}


\subsubsection*{Interference Measurements Update}

To measure interference, the \ac{BS} should schedule an empty UE-specific \acs{RS} for interference measurements. It should result in measuring the power received by the interfering sources. The main drawback is the outdatedness of the measurement since in takes around 4 TTIs until the information is available. Therefore, when the interference measurement is available, it refers to e.g. 4 TTIs ago. 

To simulate this process, we report the experienced interference from transmission that occurred $\tau_\text{TTI}$ TTIs back. 

A major disadvantage of estimating the interference in this manner comes from the fact that the experienced interference is extremely dependent on current scheduling. If the scheduled UEs or beamformers in use change, then it is expected a major change in the experienced interference to take place, thus possibly rendering the measurement completely invalid. We foresee precise interference estimation algorithms, perhaps driven by learning mechanisms, to be a future direction of work. We discuss this matter further in Section \ref{sec:future-work}. 

Before continuing to the update of the scheduling information, it is worth introducing two steps used more than once by our model of the network equipment, the link adaptation mechanism and the instantaneous bit rate computation from an SINR. 

\subsection*{Link Adaptation}
\label{sec:olla}

An intuitively important step is to choose which MCS to use for transmission. Since choosing one too high leads to only errors and one too low wastes resources, this choice must be on par with the channel as often as possible. One smart mechanism to achieve this adapts the MCS choice according with block errors.

We called it the \ac{OLLA} mechanism and it is UE-specific. Every time a MCS is estimated, it is adjusted with the OLLA parameter as a last step. Each OLLA parameter $\Delta_{OLLA}$ is initialised at zero and is updated in every TTI the given UE is scheduled. When a \ac{TB} scheduled to/from is successfully transmitted, the OLLA parameter is updated according with Equation \eqref{eq:ola_update1_success}, but if the block has errors, Equation \eqref{eq:ola_update1_fail} is used instead.


\begin{equation} \label{eq:ola_update1_success}
    \Delta_{OLLA} = \Delta_{OLLA} + BLER_0 \times \gamma_{OLLA}
\end{equation}

\begin{equation} \label{eq:ola_update1_fail}
    \Delta_{OLLA} = \Delta_{OLLA} - (1 - BLER_0) \times \gamma_{OLLA}
\end{equation}


Observe the subtlety of the asymmetry in update. The term that multiplies the step size $\gamma_{OLLA}$ is much bigger in \eqref{eq:ola_update1_fail} than in \eqref{eq:ola_update1_success}, since $BLER_0$ is usually 0.1 or smaller. It is a defensive approach, to take bigger steps towards more conservative MCSs when there are errors because it is always better to have some bitrate than no bitrate. Contrarily, the progression to increasing the MCS is slower. 


The OLLA parameter adjusts the MCS choice by flipping an appropriately biased coin and adding either $\floor{\Delta_{OLLA}}$ or $\ceil{\Delta_{OLLA}}$ to the CQI index estimated in the previous step. An appropriately biased coin in this situation is a coin that selects to round down the OLLA parameter with a probability of $\ceil{\Delta_{OLLA}} - \Delta_{OLLA}$. This makes sense because $\Delta_{OLLA}$ is decreased when a block has errors, thus making more likely that the MCS is reduced when the link has worse quality than expected. When the block does not have errors, it makes it more likely to increase the MCS estimate, such that a good link condition can be taken advantage of to increase the bitrate. Note that this formulation still works as supposed for negative values, i.e. the OLLA mechanism works for increasing and decreasing the MCS.


\subsection*{Instantaneous Bit rate}

To compute the instantaneous bit rate allows us to quantify the value of serving each user. Then we can weigh options against each other regarding fairness, maximum aggregated throughput, or likelihood of fulfilling latency constraints. Therefore, computing estimated and realised bit rate is fundamental to the operation of this wireless system.

The SINR is used to choose the MCS from the MCS curves represented in Figure \ref{fig:blercurves}, and equations in Appendix \ref{ap:blercurves}. The point at which each MCS curve intercepts the BLER probability of 10\% is marked, and the MCS that corresponds to each CQI index is in Table \ref{tab:mcs}. The MCS choice consists on selecting the first MCS that achieves a lower percentage of block errors than the \ac{BLER} target $BLER_0$ is chosen. Usual values for $BLER_0$ are 10\% or lower. 


\image{SLS/MCS_final_res300.png}{BLER curves for all MCSs. Simulated with Vienna Link-Level Simulator \cite{Vienna5GLLS}.}{fig:blercurves}{.37}


The selected MCS is then adjusted with the link adaptation parameter as described in Subsection \ref{sec:olla}. The resultant MCS tells us the number of bits in a symbol $N_{bits}^{symb}$, which can be computed from the modulation order M, through $\log_2(M)$. To compute the bits per PRB we assume all symbols/REs in a PBR are used for data, i.e. $N_{symb}^{PRB} = 168$, we multiply by $N_{bits}^{symb}$ and account for the code rate that makes further reduces the quantity of data transmitted. In essence, Equation \eqref{eq:bitrate} computes the bit rate by dividing the number of bits transmitted in a PRB by the duration of that PRB, which corresponds to a slot duration $T_{slot, \mu}$, that depends on the numerology $\mu$.

\begin{equation} \label{eq:bitrate}
    R_b = \frac{N_{bits}^{symb} \times N_{symb}^{PRB} \times R_{c}}{T_{slot, \mu}} 
\end{equation}

To counterbalance the excessive assumptions, like assuming all symbols are used for data, we account for all bit rate reductions, namely due to overheads and self-contained slots and channel state information, respectively, by multiplying the efficiencies $\eta_{OH}$, $\eta_{slot}$ and $\eta_{CSI}$. Equation \eqref{eq:eff} has the final bit rate efficiency $\eta$. An estimation for the instantaneous throughput $R$ is $R = R_b \times \eta$.


\begin{equation} \label{eq:eff}
    \eta = \eta_{OH} \times \eta_{slot} \times \eta_{CSI}
\end{equation}




\begin{comment}
Table \ref{tab:all_bitrates} is obtained by using Equation \eqref{eq:bitrate} for $\eta = 1$ for different numerologies.



\begin{table}[h]
    \centering
    \caption{Maximum achievable bitrates per PRB, for all numerologies.}
    \label{tab:all_bitrates}
    \begin{tabular}{cccc|c|c|c|c|}
    \cline{5-8}
                             &                        &                          &         & \multicolumn{4}{c|}{Bit Rates {[}kbps{]}} \\ \hline
    \multicolumn{1}{|c|}{CQI} &
      \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Bits per \\ Symbol\end{tabular}} &
      \multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}Code Rate \\ x 1024\end{tabular}} &
      \begin{tabular}[c]{@{}c@{}}bits \\ per PRB\end{tabular} &
      $\mu = 0$ &
      $\mu = 1$ &
      $\mu = 2$ &
      $\mu = 3$ \\ \hline
    \multicolumn{1}{|c|}{0}  & \multicolumn{2}{c|}{out of range}                 & 0       & 0        & 0        & 0        & 0        \\ \hline
    \multicolumn{1}{|c|}{1}  & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{78}  & 25.59   & 25.59    & 51.19    & 102.38   & 204.75   \\ \hline
    \multicolumn{1}{|c|}{2}  & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{193} & 63.33   & 63.33    & 126.66   & 253.31   & 506.63   \\ \hline
    \multicolumn{1}{|c|}{3}  & \multicolumn{1}{c|}{2} & \multicolumn{1}{c|}{449} & 147.33  & 147.33   & 294.66   & 589.31   & 1178.63  \\ \hline
    \multicolumn{1}{|c|}{4}  & \multicolumn{1}{c|}{4} & \multicolumn{1}{c|}{378} & 248.06  & 248.06   & 496.13   & 992.25   & 1984.50  \\ \hline
    \multicolumn{1}{|c|}{5}  & \multicolumn{1}{c|}{4} & \multicolumn{1}{c|}{490} & 321.56  & 321.56   & 643.13   & 1286.25  & 2572.50  \\ \hline
    \multicolumn{1}{|c|}{6}  & \multicolumn{1}{c|}{4} & \multicolumn{1}{c|}{616} & 404.25  & 404.25   & 808.50   & 1617.00  & 3234.00  \\ \hline
    \multicolumn{1}{|c|}{7}  & \multicolumn{1}{c|}{6} & \multicolumn{1}{c|}{466} & 458.72  & 458.72   & 917.44   & 1834.88  & 3669.75  \\ \hline
    \multicolumn{1}{|c|}{8}  & \multicolumn{1}{c|}{6} & \multicolumn{1}{c|}{567} & 558.14  & 558.14   & 1116.28  & 2232.56  & 4465.13  \\ \hline
    \multicolumn{1}{|c|}{9}  & \multicolumn{1}{c|}{6} & \multicolumn{1}{c|}{666} & 655.59  & 655.59   & 1311.19  & 2622.38  & 5244.75  \\ \hline
    \multicolumn{1}{|c|}{10} & \multicolumn{1}{c|}{6} & \multicolumn{1}{c|}{772} & 759.94  & 759.94   & 1519.88  & 3039.75  & 6079.50  \\ \hline
    \multicolumn{1}{|c|}{11} & \multicolumn{1}{c|}{6} & \multicolumn{1}{c|}{873} & 859.36  & 859.36   & 1718.72  & 3437.44  & 6874.88  \\ \hline
    \multicolumn{1}{|c|}{12} & \multicolumn{1}{c|}{8} & \multicolumn{1}{c|}{711} & 933.19  & 933.19   & 1866.38  & 3732.75  & 7465.50  \\ \hline
    \multicolumn{1}{|c|}{13} & \multicolumn{1}{c|}{8} & \multicolumn{1}{c|}{797} & 1046.06 & 1046.06  & 2092.13  & 4184.25  & 8368.50  \\ \hline
    \multicolumn{1}{|c|}{14} & \multicolumn{1}{c|}{8} & \multicolumn{1}{c|}{885} & 1161.56 & 1161.56  & 2323.13  & 4646.25  & 9292.50  \\ \hline
    \multicolumn{1}{|c|}{15} & \multicolumn{1}{c|}{8} & \multicolumn{1}{c|}{948} & 1244.25 & 1244.25  & 2488.50  & 4977.00  & 9954.00  \\ \hline
    \end{tabular}
\end{table}
\end{comment}





\subsection*{Scheduler} \label{sec:scheduler}
A scheduler task is to attribute priorities to UEs according to a trade-off of resource sharing fairness, achieving the maximum instantaneous aggregated throughput, or attain the lower average latencies, to name a few. These priorities allow us to select UEs by order of importance according to the weighted trade-off relation we choose. 

The most common and widely used scheduler is the \ac{PF}, presented in \eqref{eq:pf}. \ac{PF} weights the instantaneous $R$ and average $\overline{R}$ throughputs to balance immediate reward and fairness across users. The average $\overline{R}$ is computed across a $t_w$ TTI window - Equation \eqref{eq:pf2} shows how it is updated as long as $t \geq t_w$, otherwise, $t_w = t$ is used with the same expression.

\begin{equation} \label{eq:pf}
    p = \frac{R}{\overline{R}}
\end{equation}

\begin{equation} \label{eq:pf2}
    \overline{R}(t) = \left( 1 - \frac{1}{t_w} \right) \overline{R} (t-1) + \frac{1}{t_w} R(t-1)
\end{equation}

As seen, PF does not consider latencies. Yet, for our case where each user has the same amount of transmitted and received data, the PF acts as a latency-aware scheduler by weighting fairness heavily, not leaving any user waiting for long. However, it may not perform as well as latency-aware alternatives.

Two latency-aware alternatives are \ac{M-LWDF} \cite{scheduler_performance_eval} and \ac{EXP/PF} \cite{exp_algorithm}. 
The first is almost as simple as the PF, only weighting the \ac{HOL} latency as well. \ac{EXP/PF} is more complex and considers a maximum delay and increases priorities exponentially as latencies approach the limit. Both use the PF ratio described in \eqref{eq:pf}. 
\ac{M-LWDF} outperforms \ac{EXP/PF} in practically every scenario \cite{scheduler_performance_eval}, unless when there is serious dispute for resources. Therefore, both \ac{M-LWDF} and \ac{EXP/PF} may prove to be good options in the future.
\subsection{User Scheduling}

Analogous to the CSI update procedure, the scheduling information is only updated every $N^{SCH}_{slots}$ TTIs. An update on the scheduling information consists on refreshing which UEs are considered for scheduling and which BS panels are used. This choice is simple: only UEs with non-empty buffers are examined to be part of the scheduled UEs list; and each UE is served by the BS panel with the best beam pair to that UE. Then a more complex procedure takes place, the derivation of the MCS for transmission to certain UEs and in specific time-frequency resources.

MCS derivation, along with UE scheduling and resource allocation can be summarised in some steps.

\subsubsection*{SINR Estimation}

The received powers for the best $N_{CSI}$ beams have been reported in the CSI acquisition step, as well as the experienced interference, although both are outdated. Also, the channel gain can be derived directly knowing the transmit power that was used. Thus, we assume an equal distribution of the maximum transmit power at the BS $P_{t, max} ^ {BS}$ over the number of scheduled UEs with non-empty buffers. And the only missing piece in the SINR expression is the noise. 

We use wideband scheduling, i.e. allocating all available spectrum to every transmission, relying in spatial separation to prevent excessive interference. Therefore, assuming $B$ to be the system bandwidth, using thermal noise we would get a noise power $P_N$ given by Equation \eqref{eq:noise}, with the Boltzmann constant $k_B = 1.380649 \times 10^{-23}$ J/K, the noise temperature $T$ and an upscaling with the receivers' noise figure $NF_r$. All hardware imperfections are abstracted by considering noise figures in the \acs{BS} and in the \acsp{UE}, respectively, $NF_{BS}$ and $NF_{UE}$, in dB.


\begin{equation} \label{eq:noise}
    P_N = k_B T B \times 10^{\frac{NF_r}{10}}
\end{equation}

To summarise, the expression used for SINR estimation uses information from $\tau_{CSI}$ TTIs ago on the received power $P_s$ and total interference $I$. See Equation \ref{eq:sinr_estimation}

\begin{equation} \label{eq:sinr_estimation}
    \hat{SINR_{eff}} = \frac{\hat{P}_s}{\hat{I} + P_N} 
\end{equation}


\subsubsection*{Compute UE Priorities with Scheduler}
UE priorities are computed based on the estimated instantaneous bitrate, the average bitrate across time, and, depending on the scheduler, head of queue delay and other metrics. Based on latency requirements, in an attempt to have a fair and optimal system, a positive scalar priority is given to each user. See Section \ref{sec:scheduler} for details on how each scheduler works. Having options between schedulers allows us to know which makes the best decisions based on the achieved performance.


\subsubsection*{Co-schedule users}
This step lists the users to be scheduled together until the next update to the schedule. The co-scheduling rule for a single-BS-panel operation is to add one UE layer at a time to the list, by order of \ac{UE} priority (computed in the previous step), if the best beams used for those layers are compatible with the previously added \ac{UE} layers. And we define as compatible beams when the BS-side beam, belonging to the \ac{GoB} is at least than $\kappa$ beams apart, with $\kappa \in \mathbb{N}_0$. If $\kappa$ is 0, then the all layers are accepted. If $\kappa = 1$, then the beams must be different - adjacent beams have a distance of 1, so are still used together. Beams located diagonally adjacent of the \ac{GoB} are considered to have a distance of 2, hence they may be co-scheduled when $\kappa \leq 2$. Figure \ref{fig:beam-rule} illustrates the beams that cannot be co-scheduled with certain values of $\kappa$, representing in filled circles as incompatible beams, and empty circles as compatible beams with the central orange beam. More generally, the beam distance is defined by the sum of absolute differences of the beam indices in the grid. Mathematically, the beamformers $\bm{w}_{i,j}$ and $\bm{w}'_{i',j'}$, having $(i,j)$ and $(i', j')$ as the GoB indices, respectively, are compatible if $|i-i'| + |j - j'| \geq \kappa$.
    
\image{SLS/mumimo-beam-rule.png}{Beam co-scheduling incompatibility distance.}{fig:beam-rule}{.5}

In this step there is space for more elaborate algorithms that attempt to choose different combinations of the best $N_{CSI}$ beams of each user, in an attempt to maximise the metrics we care about. Of course, if scheduling one more user considerably reduces the quality of the channel to many others, it is likely not worth doing.


\subsubsection*{Power Control}
Depending on the beamforming strategy, it may be necessary to scale down all precoders due to excessive power per antenna constraints. This, however, does not apply to our case because beam-steering beamformers always have uniform amplitude. The power control process in the downlink is as simple as distributing the maximum total transmit power equally amongst the scheduled UEs.
    
\subsubsection*{Final MCS}

By now the transmit powers to each user is more accurately defined and the beam pairs are also fixed. Therefore, we obtain an estimation of the SINR for each user, and the MCS to be used for each transmission.

This step concludes the required scheduling procedure. Next follows all computations to simulate a transmission. But, much like previously, we need to introduce two mechanisms in detail before approaching the transmission section. These are an SINR framework to compute the realised SINR in each PRB and an SINR aggregation algorithm to convert vectors of SINRs per PRBs to an effective SINR that characterises the quality of the transmission.


\subsection*{Multi-layer SINR Framework with Beamforming}
\label{sec:sinr_framework}

Although the rest of the network equipment modelling has minor simplifications for single-layer transmission, for future purposes it is derived a multi-layer framework. 

To accurately compute the SINR experienced during a transmission, for each scheduled \acs{UE} and accounting for different channel responses in each \acs{PRB} of the assigned bandwidth, it is crucial to know what is the power received from any transmitter.


Let $l$ be a layer connecting a set of antennas in a BS $b$ to a set of antennas in a UE $u$, with $P_{t, l}$ the transmit power and $P_{r, l}$ is the received power in that layer. Then, let $P_{r, ll'}$ be the power received by the layer $l$ receiver using the combiner $\bm{w}_{r, l}$, transmitted by the layer $l'$ transmitter using the precoder $\bm{w}_{t, l'}$, with $\bm{H}_{ll'}$ the matrix that connects the receiver and the transmitter. Equation \eqref{eq:general_rx_pow} shows these quantities are related.

\begin{equation} \label{eq:general_rx_pow}
    P_{r, ll'} = P_{t, l'} \left| \bm{w}_{r, l} \cdot \bm{H}_{ll'} \cdot \bm{w}_{t, l'} \right|^2        
\end{equation}

The powers are scalars, $\bm{w}_{r, l}$ is a $1 \times N_r$ vector, $\bm{w}_{t, l'}$ is $N_t \times 1$ vector and $\bm{H}_{ll'}$ is a $N_r \times N_t$ matrix, where $N_t$ and $N_r$ are the number of antenna elements at the transmitter and receiver antenna arrays, respectively.

Knowing how to calculate this quantity we can compute the powers of all parts of the SINR expression on a PRB-basis: the signal $P_s$, the intra-cell interference $P_{IaCI}$, the inter-cell interference $P_{IeCI}$, the inter-layer interference $P_{ILI}$ and the noise $P_N$. Equation \eqref{eq:simple_SINR} the expression for the SINR in a given PRB. Subsequently we present equations for each quantity in the SINR expression, along with the rationale behind them. 


\begin{equation} \label{eq:simple_SINR}
    SINR = \frac{P_s}{P_{ILI} + P_{IaCI} + P_{IeCI} + P_N}
\end{equation}

Moreover, and to reiterate, all quantities mentioned in this section are time (TTI) and frequency (PRB) specific. These SINRs need to be posteriorly aggregated in an effective SINR for each transmission in the given TTI. We choose drop the $i$ index to simplify notation, as we did with the TTI since this chapter is TTI-specific.

The received signal power $P_s$ is in Equation \eqref{eq:sig_pow}.

\begin{equation} \label{eq:sig_pow}
    P_s = P_{r, ll} 
\end{equation}

%ILI

In case of multi-layer transmission, other layers scheduled to/from the same UE may interfere among themselves and the power of inter-layer interference $P_{ILI}$ accounts for this interference by summing the interferences caused in layer $l$ by every other layer $l'$ scheduled between BS $b$ and UE $u$. See Equation \eqref{eq:ili}, where $\mathcal{L}_{bu}$ is the set of layers scheduled between BS $b$ and UE $u$.

\begin{equation} \label{eq:ili}
    P_{ILI} = \sum_{\subalign{l&' \in \hspace{.05cm} \mathcal{L}_{bu} \\ &l' \neq l \\ \hspace{0.25cm} &}} P_{r, ll'} 
\end{equation}

% IaCI

Interference power contributions from the same cell/BS come from every transmission that takes place to other UEs in the same cell/served by the same BS. See Equation \eqref{eq:iaci}, where $\mathcal{U}_{b}$ is the set of users served by BS $b$.

\begin{equation} \label{eq:iaci}
    P_{IaLI} = \mathlarger{\sum}_{\subalign{u' &\in \hspace{.05cm} \mathcal{U}_{b} \\ u'& \neq \hspace{.05cm} u}} \hspace{-0.1cm} \sum_{\subalign{l' &\in \hspace{.05cm} \mathcal{L}_{bu'} \\ \hspace{0.40cm} &}} \hspace{-0.1cm} P_{r, ll'} 
\end{equation}

% IeCI
Interference contributions from outside the cell come from all non-serving BSs, all UEs and in all layers. We see this Equation \eqref{eq:ieci}, where $\mathcal{B}$ is the set of all BS (or BS panels) in the system.

\begin{equation} \label{eq:ieci}
    P_{IeCI} = \mathlarger{\mathlarger{\sum}}_{\substack{b' \in \hspace{.05cm} \mathcal{B} \\ b' \neq b}} \ \mathlarger{\sum}_{\ u' \in \hspace{.05cm} \mathcal{U}_{b'}} \hspace{-0.2cm} \sum_{\subalign{&l' \in \hspace{.05cm} \mathcal{L}_{b'u'} \\ \hspace{0.25cm} &}} \hspace{-0.1cm} P_{r, ll'} 
\end{equation}

% PN
The noise power $P_N$ is computed according with thermal noise expression in \ref{eq:noise}, using the bandwidth of a single PRB, which depends on the numerology as evidenced in Table \ref{tab:num}.

This framework is also applicable when several BS are jointly serving one user, or when one user is transmitting to several BS simultaneously, i.e. Distributed-MIMO (D-MIMO). This is true because we simply account for power contributions, abstracting from the content of the spatial streams.


\subsection*{Mutual Information Effective SINR Mapping}
\label{sec:miesm}

\acs{MI-ESM} is an SINR aggregation technique that allows us to attribute one SINR to a transmission where the quality of the channel varies across the transmission band, namely across PRBs. We choose this SINR mapping strategy because \cite{1656798, 4657235, 5982870, 6008103, miesm1} show that it unquestionably achieves the very good results without the need of calibration for different MCSs. Equation \eqref{eq:miesm} sums how it works.

\begin{equation} \label{eq:miesm}
    SINR_{eff} = I_k^{-1} \left( \frac{1}{N} \sum_{i=1}^N I_k\left(SINR_i\right)\right)
\end{equation}

Above, $I_k$ is the information function that for a given SINR and MCS (with $k$ bits per symbol) gives the bits of information that are conceivably extracted for a transmission with that SINR. For low SINRs, the mutual information is practically zero. As the SINR grows, the quantity of information bits extracted approaches $k$. Appendix \ref{ap:miesm} goes into further detail on the mutual information function works.  

Therefore, Equation \eqref{eq:miesm} obtains the mutual information achievable in each PRB, averages it and computes the SINR that would achieve that average information. Thus, the effective SINR is determined as the SINR that would yield this average mutual information if it were applied on all PRBs. 


\subsection{Transmission Realisation}

Here we obtain the outcomes of the realised transmissions. Firstly, we calculate the number of TBs in which data is separated for transmission, based on the estimated bits to transmit. Secondly, the SINRs each UE experienced in each PRB are computed and then we present how these SINRs can be aggregated in something more easily useable to conclude on overall channel quality, an effective SINR. Finally, effective SINRs result in the success or failure of the transmitted transport blocks according with the MCS used for transmission and then the link quality adaptation mechanism is updated appropriately, as well as buffers and other indicators, such as schedulers fairness indicators, to be used in upcoming transmissions to assure a balanced operation of the system in line with the result of the transmission in the present TTI. As per usual, the steps follow.


\subsubsection*{Transport Block Size Calculation}

To obtain the \ac{TBS}, essentially three ways have been modelled and need to be assessed in simulations. The first, is to consider the same number of TBs in every transmission, $N_{TB}$. Therefore the numbers of bits to be transmitted $N_{bits, bul}$ is divided equally over TBs and the size of each TB is the same, see Equation \eqref{eq:tbs1}.


\begin{equation} \label{eq:tbs1}
    S_{TB} = \ceil{N_{bits, bul}/N_{TB}}    
\end{equation}

The second is to consider a maximum TBS $S_{TB, max}$, obtain $N_{TB}$ from Equation \eqref{eq:tbs2} and then use Equation \eqref{eq:tbs1}. And the third method is to follow the list of steps described in \cite{3gpp-codebooks}, making the Transport Block Size depend on the number of layers $\#\mathcal{L}_{bu}$, modulations order $M$, code rate $R_c$, number of allocated PRBs $N_{PRB, bul}$ and transmission duration, which we assume to be always $T_{slot}$.

\begin{equation} \label{eq:tbs2}
    N_{TB} = \ceil{N_{bits, bul}/S_{TB, max}}
\end{equation}


% link for TBS calculation: http://www.techplayon.com/5g-nr-transport-block-size-tbs-calculation/ 

This such manner, $N_{TB}$ TBs are sent and the experienced bit rates depend on how many of them are delivered with no errors. If there are no errors, the bit rate computed in Equation \eqref{eq:bitrate} are achieved, otherwise only a fraction of that bit rate is achieves, corresponding to the successfully transmitted TBs over total TBs.

\subsubsection*{Compute and Aggregate Realised SINR}
Making use of the channel coefficients, we use the transmit powers and scheduled transmissions using certain beam pairs to compute the realised SINR per PRB, as described in the SINR framework described in \ref{sec:sinr_framework}. Then we aggregate it over the all PRBs into an effective SINR, by applying the procedure described in in \ref{sec:miesm}.

\subsubsection*{Compute Block Errors}

Subsequently, with the effective SINR $SINR_{eff}$ and the MCS used for the transmission, we look at the correspondent MCS curve in Figure \ref{fig:blercurves} and get the resultant $BLER$.

Then we flip a \acs{BLER}-biased coin to determine whether each block was well received or not.


\subsubsection*{Update Link Adaptation, Buffers and Performance Indicators}

Firstly, the link adaptation mechanism is updated based on the block errors in accordance with subsection \ref{sec:olla}. 

Then, the information that was successfully transmitted needs to be removed from the buffers. We model an ordered buffer where the information in one transport block has a direct mapping to certain packets. Therefore if that TB gets lost, that packet stays in the buffer.

This means the BLER may cause packets to be arrive out of order. This phenomenon is represented in Figure \ref{fig:buf} where the size of a TB is set to the same size as a packet for illustration purposes. We see the bits in the transport blocks that didn't arrive successfully are kept in the transmission buffer. Therefore, if those bits are successfully sent in the future, they would be out of order. Note that this is something common in packet networks. Successfully transmitted TBs get their share of packets removed from the buffers.


\image{SLS/ordered_buffer.png}{Buffer state before and after a transmission, with $S_{TB} = S_{packet}$.}{fig:buf}{.4}

These modelling considerations make the system considerably more realistic. It increases the likelihood that a packet get discarded due to excessive delay, so the latencies supported in a given scenario are higher.

Finally, the experienced bit rates are used to update the average bit rate over time used by the scheduler to influence what UEs are given more importance to serve in light not only of obtaining a fair resource allocation, but also to weigh and decide priorities e.g. regarding latencies versus throughputs.

\subsection*{Conclusion}

In this section we followed the required steps to perform data transmission. We started with TTI identification and soon followed Slot format. Then, we modelled CSI acquisition and presented an intuitive way of creating a \ac{GoB}, which we made use throughout the section. Afterwards, we presented Link Adaptation and Instantaneous Bit Rate procedures given the important role they play in user scheduling. Subsequently we went through the user scheduling steps. Finally, we introduced a flexible SINR framework and a well known SINR aggregation algorithm, and used them to simulate a data transmission.


Next section we simulate single and multi-user scenarios and assess the relations between several parameters described in this section. 

